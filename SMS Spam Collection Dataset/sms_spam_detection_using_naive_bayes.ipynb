{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import names\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report,roc_auc_score,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'E:\\programming\\dataset\\sms_spam_kaggle\\spam.csv',encoding='ISO-8859-1')\n",
    "#when i try to load it simply, it gave me a unicodeDeocode error, i searched up the probelm, \n",
    "#and got the solution to use encoding='ISO-8859-1', although i don't know why but it gave me\n",
    "#some extra columns which i removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 5)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['v1','v2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['v2'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the text and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remvogin all words which contrain number or special characters\n",
    "#lemmatizing the words\n",
    "#removing human names from the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def letters_only(astr):\n",
    "    return astr.isalpha()\n",
    "\n",
    "all_names = names.words()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = []\n",
    "for i in range(len(data)):\n",
    "    sentence = data['v2'][i].split()\n",
    "    cleaned_text.append(\" \".join([lemmatizer.lemmatize(word) for word in sentence if letters_only(word) and not word in all_names]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['v2'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Go until jurong Available only in bugis n great world la e Cine there got amore'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cleaned_text'] = cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>Go until jurong Available only in bugis n grea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok Joking wif u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Free entry in a wkly comp to win FA Cup final ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say so early U c already then</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Nah I think he go to he life around here though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   ham                      Ok lar... Joking wif u oni...   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   ham  U dun say so early hor... U c already then say...   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  Go until jurong Available only in bugis n grea...  \n",
       "1                                    Ok Joking wif u  \n",
       "2  Free entry in a wkly comp to win FA Cup final ...  \n",
       "3                U dun say so early U c already then  \n",
       "4    Nah I think he go to he life around here though  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v1              0\n",
       "v2              0\n",
       "cleaned_text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#looking for any missing values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we don't have any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label encoding for target\n",
    "encoding = {'ham':0,'spam':1}\n",
    "data['target'] = data['v1'].map(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>Go until jurong Available only in bugis n grea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok Joking wif u</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Free entry in a wkly comp to win FA Cup final ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say so early U c already then</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Nah I think he go to he life around here though</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   ham                      Ok lar... Joking wif u oni...   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   ham  U dun say so early hor... U c already then say...   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                        cleaned_text  target  \n",
       "0  Go until jurong Available only in bugis n grea...       0  \n",
       "1                                    Ok Joking wif u       0  \n",
       "2  Free entry in a wkly comp to win FA Cup final ...       1  \n",
       "3                U dun say so early U c already then       0  \n",
       "4    Nah I think he go to he life around here though       0  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we don't need the v1 and v2 colunbs\n",
    "data.drop(['v1','v2'],axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong Available only in bugis n grea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok Joking wif u</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in a wkly comp to win FA Cup final ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early U c already then</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I think he go to he life around here though</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        cleaned_text  target\n",
       "0  Go until jurong Available only in bugis n grea...       0\n",
       "1                                    Ok Joking wif u       0\n",
       "2  Free entry in a wkly comp to win FA Cup final ...       1\n",
       "3                U dun say so early U c already then       0\n",
       "4    Nah I think he go to he life around here though       0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(data['cleaned_text'],data['target'],test_size = 0.3,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3900,) (1672,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(stop_words = 'english',max_features = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectorized = cv.fit_transform(X_train)\n",
    "test_vectorized = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3900, 500) (1672, 500)\n"
     ]
    }
   ],
   "source": [
    "#train_vectorized and test_vectorized are spares metrics\n",
    "print(train_vectorized.shape,test_vectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['able', 'abt', 'account', 'actually', 'address', 'afternoon', 'aight', 'alright', 'angry', 'answer', 'anytime', 'apply', 'ard', 'ask', 'asked', 'attempt', 'await', 'award', 'awarded', 'away', 'babe', 'baby', 'bad', 'beautiful', 'bed', 'believe', 'best', 'better', 'big', 'birthday', 'bit', 'blue', 'bonus', 'book', 'booked', 'bored', 'bout', 'box', 'boy', 'break', 'bring', 'bslvyl', 'bt', 'bus', 'busy', 'buy', 'called', 'caller', 'callertune', 'calling', 'came', 'camera', 'car', 'card', 'care', 'cash', 'cause', 'chance', 'change', 'charge', 'chat', 'check', 'choose', 'claim', 'class', 'close', 'code', 'collect', 'colour', 'come', 'coming', 'comp', 'company', 'completely', 'congrats', 'congratulations', 'contact', 'content', 'cool', 'copy', 'cos', 'cost', 'couple', 'coz', 'crave', 'currently', 'customer', 'da', 'dad', 'darlin', 'dat', 'date', 'dating', 'day', 'dear', 'decided', 'den', 'did', 'didnt', 'dinner', 'direct', 'dis', 'dnt', 'doe', 'dogging', 'doing', 'dont', 'double', 'download', 'draw', 'dream', 'drink', 'drive', 'driving', 'drop', 'drug', 'dude', 'dun', 'dunno', 'early', 'easy', 'eat', 'end', 'enjoy', 'enter', 'entry', 'evening', 'expires', 'extra', 'face', 'fall', 'family', 'fancy', 'far', 'feel', 'feeling', 'felt', 'figure', 'final', 'finally', 'fine', 'finish', 'finished', 'forget', 'forgot', 'fr', 'free', 'friend', 'friends', 'friendship', 'frnd', 'fuck', 'fucking', 'fun', 'game', 'gas', 'gd', 'getting', 'gift', 'girl', 'god', 'goin', 'going', 'gonna', 'good', 'got', 'great', 'guaranteed', 'gud', 'guess', 'guy', 'ha', 'haf', 'haha', 'hair', 'half', 'happen', 'happened', 'happy', 'hard', 'hav', 'havent', 'having', 'head', 'hear', 'heart', 'hello', 'help', 'hey', 'hi', 'hmv', 'hold', 'holiday', 'home', 'hope', 'hot', 'hour', 'house', 'hows', 'hurt', 'id', 'identifier', 'ill', 'im', 'important', 'invited', 'job', 'join', 'jus', 'just', 'juz', 'kiss', 'knew', 'know', 'knw', 'land', 'landline', 'late', 'later', 'latest', 'leave', 'leaving', 'left', 'lesson', 'let', 'life', 'light', 'like', 'line', 'little', 'live', 'log', 'lol', 'long', 'look', 'looking', 'lor', 'lot', 'love', 'lovely', 'lunch', 'luv', 'mail', 'make', 'making', 'man', 'match', 'mate', 'maybe', 'mean', 'meet', 'meeting', 'message', 'met', 'min', 'mind', 'minute', 'miss', 'missed', 'missing', 'mob', 'mobile', 'mom', 'moment', 'money', 'month', 'morning', 'movie', 'msg', 'mu', 'mum', 'music', 'need', 'network', 'new', 'news', 'nice', 'night', 'nite', 'noe', 'nokia', 'number', 'offer', 'office', 'oh', 'ok', 'okie', 'old', 'online', 'open', 'operator', 'opt', 'orange', 'oso', 'outside', 'pa', 'pain', 'party', 'pay', 'people', 'person', 'phone', 'pic', 'pick', 'picking', 'place', 'plan', 'play', 'player', 'pls', 'plus', 'plz', 'po', 'pobox', 'point', 'post', 'pound', 'press', 'price', 'prize', 'probably', 'problem', 'project', 'promise', 'pub', 'question', 'quite', 'rate', 'reach', 'read', 'reading', 'ready', 'real', 'really', 'reason', 'receive', 'remember', 'reply', 'right', 'ring', 'ringtone', 'room', 'run', 'sad', 'said', 'sat', 'saw', 'say', 'saying', 'sch', 'school', 'search', 'second', 'secret', 'seeing', 'selected', 'send', 'sent', 'service', 'set', 'sex', 'sexy', 'shall', 'shit', 'shop', 'shopping', 'si', 'sleep', 'sm', 'smile', 'smiling', 'smoke', 'sms', 'smth', 'somebody', 'song', 'soon', 'sorry', 'sound', 'speak', 'special', 'st', 'start', 'started', 'statement', 'stay', 'stop', 'store', 'story', 'stuff', 'summer', 'support', 'supposed', 'sure', 'surprise', 'sweet', 'taking', 'talk', 'talking', 'tampa', 'teach', 'tell', 'test', 'text', 'th', 'thank', 'thanks', 'thanx', 'thats', 'thing', 'think', 'thk', 'thought', 'ticket', 'til', 'till', 'time', 'tmr', 'today', 'todays', 'told', 'tomorrow', 'tone', 'tonight', 'took', 'tot', 'touch', 'town', 'treat', 'tried', 'trip', 'try', 'trying', 'tv', 'txt', 'txting', 'type', 'uncle', 'unlimited', 'unsubscribe', 'update', 'ur', 'urgent', 'use', 'valid', 'video', 'visit', 'voucher', 'wa', 'wait', 'waiting', 'wake', 'walk', 'wan', 'wana', 'wanna', 'want', 'wanted', 'wat', 'watch', 'watching', 'way', 'week', 'weekend', 'weekly', 'wen', 'went', 'wid', 'wif', 'wife', 'wil', 'win', 'wine', 'wish', 'wit', 'wk', 'wkly', 'woke', 'won', 'wonderful', 'wont', 'word', 'work', 'working', 'world', 'worry', 'worth', 'wot', 'xmas', 'xxx', 'xy', 'ya', 'yar', 'yeah', 'year', 'yes', 'yo', 'yr', 'yup', 'ìï']\n"
     ]
    }
   ],
   "source": [
    "# we cam view the 500 features that are used\n",
    "features = cv.get_feature_names()\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic  Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alpha is the smoothing factor\n",
    "nb = MultinomialNB(alpha = 1,fit_prior = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(train_vectorized,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_probs = nb.predict_proba(test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = nb.predict(test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      1434\n",
      "           1       0.85      0.84      0.85       238\n",
      "\n",
      "    accuracy                           0.96      1672\n",
      "   macro avg       0.91      0.91      0.91      1672\n",
      "weighted avg       0.96      0.96      0.96      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test,predicted_classes)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy on test examples is 0.9569377990430622\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_test,predicted_classes)\n",
    "print('the accuracy on test examples is {}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the roc score obtained is 0.9728341127245878\n"
     ]
    }
   ],
   "source": [
    "roc_score = roc_auc_score(y_test,prediction_probs[:,1])\n",
    "print('the roc score obtained is {}'.format(roc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the best possible values of hyperparameters using k fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "k_fold = StratifiedKFold(n_splits = k)\n",
    "\n",
    "#creating numpy arrays for better slicing\n",
    "cleaned_emails_np = np.array(data['cleaned_text'])\n",
    "labels_np = np.array(data['target'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features_option = [2000,4000,8000]\n",
    "smoothing_factor_option = [0.5, 1.0, 1.5, 2.0]\n",
    "fit_prior_option = [True, False]\n",
    "auc_record = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_indices,test_indices in k_fold.split(cleaned_emails_np,labels_np):\n",
    "    X_train,X_test = cleaned_emails_np[train_indices],cleaned_emails_np[test_indices]\n",
    "    y_train,y_test = labels_np[train_indices],labels_np[test_indices]\n",
    "    for features in max_features_option:\n",
    "        if not features in auc_record:\n",
    "            auc_record[features] = {}\n",
    "        cv = CountVectorizer(stop_words = 'english',max_features = features)\n",
    "        train_doc = cv.fit_transform(X_train)\n",
    "        test_doc = cv.transform(X_test)\n",
    "        for smoothing in smoothing_factor_option:\n",
    "            if not smoothing in auc_record[features]:\n",
    "                auc_record[features][smoothing] = {}\n",
    "            for fit_prior in fit_prior_option:\n",
    "                clf = MultinomialNB(alpha=smoothing, fit_prior=fit_prior)\n",
    "                clf.fit(train_doc,y_train)\n",
    "                pred_probas = clf.predict_proba(test_doc)\n",
    "                pos_prob = pred_probas[:,1]\n",
    "                auc = roc_auc_score(y_test,pos_prob)  \n",
    "                auc_record[features][smoothing][fit_prior] \\\n",
    "                    = auc + auc_record[features][smoothing].get(fit_prior, 0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max_features   smoothing    fit_prior      auc\n",
      "2000           0.5           True        0.9699\n",
      "2000           0.5           False        0.9699\n",
      "2000           1.0           True        0.9696\n",
      "2000           1.0           False        0.9696\n",
      "2000           1.5           True        0.9689\n",
      "2000           1.5           False        0.9689\n",
      "2000           2.0           True        0.9680\n",
      "2000           2.0           False        0.9680\n",
      "4000           0.5           True        0.9735\n",
      "4000           0.5           False        0.9735\n",
      "4000           1.0           True        0.9718\n",
      "4000           1.0           False        0.9718\n",
      "4000           1.5           True        0.9698\n",
      "4000           1.5           False        0.9698\n",
      "4000           2.0           True        0.9680\n",
      "4000           2.0           False        0.9680\n",
      "8000           0.5           True        0.9733\n",
      "8000           0.5           False        0.9733\n",
      "8000           1.0           True        0.9713\n",
      "8000           1.0           False        0.9713\n",
      "8000           1.5           True        0.9690\n",
      "8000           1.5           False        0.9690\n",
      "8000           2.0           True        0.9666\n",
      "8000           2.0           False        0.9666\n"
     ]
    }
   ],
   "source": [
    "print('Max_features   smoothing    fit_prior      auc')\n",
    "for max_features,max_features_data in auc_record.items():\n",
    "    for smoothing,smoothing_data in max_features_data.items():\n",
    "        for fit_prior,auc in smoothing_data.items():\n",
    "            print(\"{0}           {1}           {2}        {3:.4f}\".format(max_features,smoothing,fit_prior,auc/k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by looking at the above information, we can find the combinations for the hyperparameters which has the maximum score \n",
    "max_features_best = 4000\n",
    "smoothing_best = 0.5\n",
    "fit_prior_best = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(data['cleaned_text'],data['target'],test_size = 0.3,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features = max_features_best,stop_words = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectorized = cv.fit_transform(X_train)\n",
    "test_vectorized = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3900, 4000) (1672, 4000)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectorized.shape,test_vectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.5, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = MultinomialNB(alpha = smoothing_best,fit_prior=fit_prior_best)\n",
    "nb.fit(train_vectorized,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = nb.predict(test_vectorized)\n",
    "predicted_probas = nb.predict_proba(test_vectorized)\n",
    "probas_spam = predicted_probas[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the roc_auc score is  0.9821194168043788\n"
     ]
    }
   ],
   "source": [
    "final_score = roc_auc_score(y_test,probas_spam)\n",
    "print('the roc_auc score is ',final_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      1434\n",
      "           1       0.89      0.89      0.89       238\n",
      "\n",
      "    accuracy                           0.97      1672\n",
      "   macro avg       0.94      0.93      0.94      1672\n",
      "weighted avg       0.97      0.97      0.97      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test,predicted_classes)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
